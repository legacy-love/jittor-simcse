{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "import sys\n",
    "from typing import Optional, List, Union, Dict, Tuple\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "import commentjson\n",
    "\n",
    "from transformers import (\n",
    "    HfArgumentParser\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast, AutoTokenizer\n",
    "import jittor as jt\n",
    "from jittor.dataset import Dataset, DataLoader\n",
    "from model import BertForCL, BertConfig\n",
    "from dataset import CLDataset\n",
    "from tool import calc_loss\n",
    "from tqdm import tqdm\n",
    "jt.flags.use_cuda = jt.has_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读取配置文件\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    tokenizer_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The local dir of tokenizer\"}\n",
    "    )\n",
    "    params_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The path of the parameters\"}\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    dataset_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The path of the dataset\"}\n",
    "    )\n",
    "    max_seq_len: int = field(\n",
    "        default=32,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences logonger\"\n",
    "            \"than this will be truncated\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "@dataclass\n",
    "class TrainingArguments:\n",
    "    temperature: int = field(\n",
    "        default=0.05,\n",
    "        metadata={\"help\": \"Temperature of Loss function\"}\n",
    "    )\n",
    "    mode: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The mode of the training. It must be \\\"supervised\\\" or \\\"unsupervised\\\".\"}\n",
    "    )\n",
    "    batch_size: int = field(\n",
    "        default=128,\n",
    "        metadata={\"help\": \"batch size\"}\n",
    "    )\n",
    "    epoch: int = field(\n",
    "        default=1,\n",
    "        metadata={\"help\": \"epoch\"}\n",
    "    )\n",
    "    learning_rate: float = field(\n",
    "        default=1e-5,\n",
    "        metadata={\"help\": \"learning_rate\"}\n",
    "    )\n",
    "    def __post_init__(self):\n",
    "        allowed_mode = [\"supervised\", \"unsupervised\"]\n",
    "        if self.mode not in allowed_mode:\n",
    "            raise ValueError(\"mode must be supervised or unsupervised\")\n",
    "\n",
    "parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n",
    "\n",
    "config_path = \"../config.jsonc\"\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config_data = commentjson.load(f)\n",
    "model_args, data_args, training_args = parser.parse_dict(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/aiuser/.cache/huggingface/datasets/text/default-2b8fc52e575fe36a/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "if training_args.mode == \"supervised\":\n",
    "    dataset = load_dataset(\"csv\", data_files=data_args.dataset_path)\n",
    "    # print(dataset['train'][0])\n",
    "elif training_args.mode == \"unsupervised\":\n",
    "    dataset = load_dataset(\"text\", data_files=data_args.dataset_path)\n",
    "    # print(dataset[\"train\"][0])\n",
    "else:\n",
    "    raise ValueError(\"The mode must be \\\"supervised\\\" or \\\"unsupervised\\\".\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args.tokenizer_dir, local_files_only=True)\n",
    "# jt.display_memory_info()\n",
    "\n",
    "training_dataset = CLDataset(dataset, tokenizer, data_args, training_args)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=training_args.batch_size)\n",
    "\n",
    "# jt.display_memory_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = BertConfig()\n",
    "model = BertForCL(bert_config).cuda()\n",
    "params_dict = jt.load(model_args.params_path)\n",
    "params_dict = {k.replace(\"LayerNorm.gamma\", \"LayerNorm.weight\"): v for k, v in params_dict.items()}\n",
    "params_dict = {k.replace(\"LayerNorm.beta\", \"LayerNorm.bias\"): v for k, v in params_dict.items()}\n",
    "model.load_state_dict(params_dict)\n",
    "params_dict = None  # 不加这行代码会导致内存泄漏，没有明白原因，可能和全局变量引用导致计算图没有释放有关"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7812 [00:00<1:25:26,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 0, loss=0.8145176768302917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 201/7812 [01:48<1:08:20,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 200, loss=0.7649548649787903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 401/7812 [03:36<1:08:19,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 400, loss=1.4548181295394897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 601/7812 [05:24<1:04:45,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 600, loss=0.7639535665512085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 801/7812 [07:13<1:03:51,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 800, loss=0.7581392526626587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1001/7812 [09:01<1:00:44,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 1000, loss=0.7716906070709229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1201/7812 [10:48<58:46,  1.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 1200, loss=0.7451072335243225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1401/7812 [12:35<58:31,  1.83it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 1400, loss=0.7633715867996216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1601/7812 [14:22<54:42,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 1600, loss=0.7469677925109863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1801/7812 [16:09<53:57,  1.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 1800, loss=0.7766804695129395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2001/7812 [17:57<51:53,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 2000, loss=0.7625852823257446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2201/7812 [19:44<49:35,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 2200, loss=0.8569320440292358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2401/7812 [21:31<47:42,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 2400, loss=0.7979599237442017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2601/7812 [23:17<46:30,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 2600, loss=0.7603951692581177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2801/7812 [25:05<45:55,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 2800, loss=0.739495038986206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3001/7812 [26:52<43:03,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 3000, loss=0.849277675151825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3201/7812 [28:40<40:56,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 3200, loss=0.8493638634681702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 3401/7812 [30:27<39:05,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 3400, loss=0.8626919984817505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 3601/7812 [32:14<38:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 3600, loss=0.743420422077179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 3801/7812 [34:02<35:33,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 3800, loss=0.7405920624732971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4001/7812 [35:49<34:21,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 4000, loss=0.7368035912513733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 4201/7812 [37:38<32:24,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 4200, loss=0.7328453063964844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 4401/7812 [39:25<30:24,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 4400, loss=0.7633770108222961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 4601/7812 [41:13<28:54,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 4600, loss=0.7377058267593384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 4801/7812 [43:01<26:47,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 4800, loss=0.7838277816772461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 5001/7812 [44:49<25:07,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 5000, loss=0.7585068941116333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 5201/7812 [46:37<25:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 5200, loss=0.7358042597770691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 5401/7812 [48:24<21:21,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 5400, loss=0.7381942868232727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 5601/7812 [50:12<19:35,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 5600, loss=0.7285133004188538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 5801/7812 [51:59<17:54,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 5800, loss=0.7320502400398254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 6001/7812 [53:46<16:07,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 6000, loss=0.7373573780059814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 6201/7812 [55:33<14:18,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 6200, loss=0.7347224354743958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 6401/7812 [57:22<12:30,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 6400, loss=1.3077831268310547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 6601/7812 [59:11<11:09,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 6600, loss=0.7240882515907288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 6801/7812 [1:00:58<09:01,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 6800, loss=0.7277665138244629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 7001/7812 [1:02:46<07:21,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 7000, loss=0.7971813678741455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 7201/7812 [1:04:34<05:26,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 7200, loss=0.7404295206069946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 7401/7812 [1:06:21<03:40,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 7400, loss=0.7279433012008667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 7601/7812 [1:08:07<01:54,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 7600, loss=0.731085479259491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 7801/7812 [1:09:55<00:05,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch_idx 7800, loss=0.7291449308395386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7813it [1:10:01,  1.86it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = jt.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "model.train()\n",
    "\n",
    "min_loss = float(\"inf\")\n",
    "best_sd = {}\n",
    "\n",
    "total_len = len(training_dataset) // training_args.batch_size\n",
    "for i in range(training_args.epoch):\n",
    "    for batch_idx, (y1, y2, y3) in enumerate(tqdm(training_dataloader, total=total_len)):\n",
    "        input_ids1 = y1[\"input_ids\"].squeeze(1)\n",
    "        token_type_ids1 = y1[\"token_type_ids\"].squeeze(1)\n",
    "        attention_mask1 = y1[\"attention_mask\"].squeeze(1)\n",
    "        input_ids2 = y2[\"input_ids\"].squeeze(1)\n",
    "        token_type_ids2 = y2[\"token_type_ids\"].squeeze(1)\n",
    "        attention_mask2 = y2[\"attention_mask\"].squeeze(1)\n",
    "\n",
    "        if training_args.mode == \"supervised\":\n",
    "            input_ids3 = y3[\"input_ids\"].squeeze(1)\n",
    "            token_type_ids3 = y3[\"token_type_ids\"].squeeze(1)\n",
    "            attention_mask3 = y3[\"attention_mask\"].squeeze(1)\n",
    "\n",
    "            _, z1 = model(input_ids1, token_type_ids1, attention_mask1)\n",
    "            _, z2 = model(input_ids2, token_type_ids2, attention_mask2)\n",
    "            _, z3 = model(input_ids3, token_type_ids3, attention_mask3)\n",
    "\n",
    "            loss = calc_loss(training_args, z1, z2, z3)\n",
    "            optimizer.step(loss)\n",
    "            jt.sync_all()\n",
    "            jt.gc()\n",
    "\n",
    "            loss = loss.detach().item()\n",
    "\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                best_sd = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "            \n",
    "        elif training_args.mode == \"unsupervised\":\n",
    "            _, z1 = model(input_ids1, token_type_ids1, attention_mask1)\n",
    "            _, z2 = model(input_ids2, token_type_ids2, attention_mask2)\n",
    "\n",
    "            loss = calc_loss(training_args, z1, z2)\n",
    "            optimizer.step(loss)\n",
    "            jt.sync_all()\n",
    "            jt.gc()\n",
    "            \n",
    "            loss = loss.detach().item()\n",
    "\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                best_sd = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            raise ValueError(\"The mode must be \\\"supervised\\\" or \\\"unsupervised\\\".\")\n",
    "\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(f\"Epoch {i}, batch_idx {batch_idx}, loss={loss}\")\n",
    "    print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss: 0.7179750204086304\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Loss: {min_loss}\")\n",
    "jt.save(best_sd,\"../ckpt/my_bert/my_bert2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jittor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
